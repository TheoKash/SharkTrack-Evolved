{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experimentation\n",
    "This notebook is designed to streamline experimentation with different models.\n",
    "\n",
    "1. Selecting a model, dataset, tracker and hyperparameters\n",
    "2. Training the model and evaluating both object detection and tracking performance\n",
    "3. Saving the results in wandb\n",
    "4. Storing the model and evaluation annotations in a folder\n",
    "5. **Investigation** of the results, detection of failure cases and model improvement\n",
    "6. **Iterating** over steps 1-5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import yolov8\n",
    "from trackers import botsort\n",
    "from data import yolo_dataset\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> run `wandb login` in terminal before running this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model, dataset, tracker and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = {\n",
    "  \"yolov8\": yolov8.YoloV8\n",
    "}\n",
    "\n",
    "trackers = {\n",
    "  'botsort': botsort.BotSort\n",
    "  }\n",
    "\n",
    "dataset_mapping = {\n",
    " \"yolov8\": yolo_dataset.YoloDataset\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_train_params = [\"architecture\", \"epochs\", \"batch_size\", \"img_size\", \"lr\", \"greyscale\", \"model_size\", \"model_path\", \"patience\", \"training_data\"]\n",
    "required_eval_params = [\"conf_threshold\", \"eval_data\", \"iou_association_threshold\", \"tracker\"]\n",
    "dynamic = [\"pretrained\", \"annotations_path\"]\n",
    "\n",
    "def construct_hyperparameters(model_name, **kwargs):\n",
    "  hyperparameters = {\n",
    "    \"model_name\": model_name\n",
    "  }\n",
    "\n",
    "  model_pretrained = False\n",
    "\n",
    "  with open(\"./assets/trained_models.json\", \"r\") as file:\n",
    "      trained_models = json.load(file)\n",
    "  assert trained_models is not None\n",
    "  \n",
    "  if model_name in trained_models:\n",
    "     model_pretrained = True\n",
    "     # Train params are already known  \n",
    "     model_train_params = trained_models[model_name]\n",
    "     assert model_train_params is not None and [param in model_train_params for param in required_train_params]\n",
    "     hyperparameters.update({param: model_train_params[param] for param in required_train_params})\n",
    "     hyperparameters.update({param: kwargs[param] for param in required_eval_params})\n",
    "\n",
    "  else:\n",
    "    # TODO: account for tf models\n",
    "    # TODO: allow for train_min, device s to be added afterwards\n",
    "    model_path = \"/vol/biomedic3/bglocker/ugproj2324/fv220/models/best.pt\"\n",
    "    assert len(kwargs) == len(required_train_params) + len(required_eval_params)\n",
    "    assert [param in kwargs for param in required_train_params + required_eval_params]\n",
    "    hyperparameters.update({**kwargs, \"path\": model_path})\n",
    "\n",
    "  hyperparameters['pretrained'] = model_pretrained\n",
    "  hyperparameters['annotations_path'] = \"/\".join(hyperparameters['model_path'].split(\"/\")[:-1]) + \"/annotations.csv\"\n",
    "\n",
    "  assert [param in hyperparameters for param in required_train_params + required_eval_params + dynamic]\n",
    "\n",
    "  return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_experimentation(hyperparameters):\n",
    "  # run = wandb.init(project=\"SharkTrack\", config=hyperparameters)\n",
    "\n",
    "  try:\n",
    "    tracker = trackers[hyperparameters['tracker']]()\n",
    "    model = architectures[hyperparameters['architecture']](hyperparameters, tracker)\n",
    "\n",
    "    data_dir = \"/vol/biomedic3/bglocker/ugproj2324/fv220/datasets/images_raw/\"\n",
    "    data_config = hyperparameters['training_data']\n",
    "    dataset = dataset_mapping[hyperparameters['architecture']](data_dir, data_config['datasets'], data_config['augmentations'])\n",
    "    print(dataset.dataset_size)\n",
    "\n",
    "    if not hyperparameters['pretrained']:\n",
    "      train_time, device = model.train(dataset)\n",
    "      # wandb.log({\"Training Time (m)\": train_time, \"Training Device\": device})\n",
    "\n",
    "    mota, motp, idf1, track_time, device =  model.evaluate()\n",
    "\n",
    "    # wandb.log({\"MOTA\": mota, \"MOTP\": motp, \"IDF1\": idf1, \"Tracking Time (m)\": track_time, \"Tracking Device\": device})\n",
    "    # TODO: add image as well, test+time and test_device\n",
    "     \n",
    "  finally: \n",
    "    pass\n",
    "    # run.finish()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'yolov8n-test', 'model_path': '/vol/biomedic3/bglocker/ugproj2324/fv220/dev/shark_locator_tests/runs/detect/yolov8m_mvd2/best.pt', 'architecture': 'yolov8', 'epochs': 5, 'batch_size': 16, 'img_size': 640, 'lr': 0.01, 'greyscale': False, 'model_size': 'n', 'patience': 10, 'training_data': {'datasets': {'rf1': 0.1, 'rf2': 0.1, 'rf3': 0.1, 'mwitt': 0.1, 'openimagesv7': 0.1, 'sl': 0.1, 'backgrounds': 0.1}, 'augmentations': ['Equalise', 'Rotate', 'Crop', 'Bbox-rotate', 'Cutout']}, 'conf_threshold': 0.2, 'eval_data': 'eval1', 'iou_association_threshold': 0.5, 'tracker': 'botsort', 'path': '/vol/biomedic3/bglocker/ugproj2324/fv220/models/best.pt', 'pretrained': False, 'annotations_path': '/vol/biomedic3/bglocker/ugproj2324/fv220/dev/shark_locator_tests/runs/detect/yolov8m_mvd2/annotations.csv'}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"yolov8n-test\"\n",
    "dataset_params = {\n",
    "  \"datasets\": {\n",
    "        \"rf1\": 0.1,\n",
    "        \"rf2\": 0.1,\n",
    "        \"rf3\": 0.1,\n",
    "        \"mwitt\": 0.1,\n",
    "        \"openimagesv7\": 0.1,\n",
    "        \"sl\": 0.1,\n",
    "        \"backgrounds\": 0.1\n",
    "  },\n",
    "  \"augmentations\": [\"Equalise\", \"Rotate\", \"Crop\", \"Bbox-rotate\", \"Cutout\"]\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "  \"model_path\": \"/vol/biomedic3/bglocker/ugproj2324/fv220/dev/shark_locator_tests/runs/detect/yolov8m_mvd2/best.pt\",\n",
    "  \"architecture\": \"yolov8\",\n",
    "  \"epochs\": 5,\n",
    "  \"batch_size\": 16,\n",
    "  \"img_size\": 640,\n",
    "  \"lr\": 0.01,\n",
    "  \"greyscale\": False,\n",
    "  \"model_size\": \"n\",\n",
    "  \"patience\": 10,\n",
    "  \"training_data\": dataset_params\n",
    "}\n",
    "\n",
    "eval_params = {\n",
    "  \"conf_threshold\": 0.2,\n",
    "  \"eval_data\": \"eval1\",\n",
    "  \"iou_association_threshold\": 0.5,\n",
    "  \"tracker\": \"botsort\"\n",
    "}\n",
    "\n",
    "hyperparameters = construct_hyperparameters(model_name, **train_params, **eval_params)\n",
    "\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised Model yolov8n-test \n",
      "rf1: original size: 1052, samples: 105 images\n",
      "rf2: original size: 4384, samples: 438 images\n",
      "rf3: original size: 3527, samples: 352 images\n",
      "mwitt: original size: 109, samples: 10 images\n",
      "openimagesv7: original size: 653, samples: 65 images\n",
      "sl: original size: 314, samples: 31 images\n",
      "backgrounds: original size: 262, samples: 26 images\n",
      "rf1 1052 0.1 105\n",
      "rf2 4384 0.1 438\n",
      "rf3 3527 0.1 352\n",
      "mwitt 109 0.1 10\n",
      "openimagesv7 653 0.1 65\n",
      "sl 314 0.1 31\n",
      "backgrounds 262 0.1 26\n",
      "{'rf1': 105, 'rf2': 438, 'rf3': 352, 'mwitt': 10, 'openimagesv7': 65, 'sl': 31, 'backgrounds': 26}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BaseTrainer.__init__() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_experimentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mmodel_experimentation\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrained\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 14\u001b[0m   train_time, device \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;66;03m# wandb.log({\"Training Time (m)\": train_time, \"Training Device\": device})\u001b[39;00m\n\u001b[1;32m     17\u001b[0m mota, motp, idf1, track_time, device \u001b[38;5;241m=\u001b[39m  model\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/fv220/dev/scripts/model_development/architectures/yolov8.py:76\u001b[0m, in \u001b[0;36mYoloV8.train\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     65\u001b[0m model_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     67\u001b[0m trainer_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: utils\u001b[38;5;241m.\u001b[39mget_torch_device(),\n\u001b[1;32m     74\u001b[0m }\n\u001b[0;32m---> 76\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDetectionTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_params\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m trainer\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mimgsz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     83\u001b[0m trainer\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/fv220/dev/scripts/model_development/architectures/yolov8.py:21\u001b[0m, in \u001b[0;36mCustomDetectionTrainer.__init__\u001b[0;34m(self, train_dataloader, val_dataloader, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, train_dataloader, val_dataloader, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_train_dataloader \u001b[38;5;241m=\u001b[39m train_dataloader\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_val_dataloader \u001b[38;5;241m=\u001b[39m val_dataloader\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseTrainer.__init__() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "model_experimentation(hyperparameters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_ml_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
